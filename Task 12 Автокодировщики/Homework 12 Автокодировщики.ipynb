{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0719ca86",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Простой-автокодировщик\" data-toc-modified-id=\"Простой-автокодировщик-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Простой автокодировщик</a></span></li><li><span><a href=\"#Автокодировщик-на-сверточной-сети\" data-toc-modified-id=\"Автокодировщик-на-сверточной-сети-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Автокодировщик на сверточной сети</a></span></li><li><span><a href=\"#Вариационный-автокодировщик-VAE\" data-toc-modified-id=\"Вариационный-автокодировщик-VAE-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Вариационный автокодировщик VAE</a></span></li><li><span><a href=\"#Зашумленный-автокодировщик\" data-toc-modified-id=\"Зашумленный-автокодировщик-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Зашумленный автокодировщик</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c660b1",
   "metadata": {},
   "source": [
    "# Простой автокодировщик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "945722ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1755f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper params\n",
    "num_epoch = 20\n",
    "cuda_device = 0\n",
    "batch_size = 128\n",
    "device = f'cuda:{cuda_device}' if cuda_device != 0 else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9688c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "tensor(0.1046, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2\n",
      "tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3\n",
      "tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4\n",
      "tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5\n",
      "tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6\n",
      "tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7\n",
      "tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8\n",
      "tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9\n",
      "tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch: 10\n",
      "tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch: 11\n",
      "tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch: 12\n",
      "tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch: 13\n",
      "tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch: 14\n",
      "tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch: 15\n",
      "tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch: 16\n",
      "tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch: 17\n",
      "tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch: 18\n",
      "tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch: 19\n",
      "tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch: 20\n",
      "tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0083, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    # 28*28 -> hidden -> out\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(0, 1)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout2 = nn.Dropout(0, 1)\n",
    "        self.linear3 = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.activation(self.linear1(x)))\n",
    "        x = self.dropout2(self.activation(self.linear2(x)))\n",
    "        x = self.activation(self.linear3(x))\n",
    "            \n",
    "        return x\n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    # encoder_out -> hidden -> 28*28\n",
    "    def __init__(self, latent_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(0, 1)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout2 = nn.Dropout(0, 1)\n",
    "        self.linear3 = nn.Linear(hidden_dim, out_dim)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.activation(self.linear1(x)))\n",
    "        x = self.dropout2(self.activation(self.linear2(x)))\n",
    "        x = self.activation(self.linear3(x))\n",
    "            \n",
    "        return x\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "def collate_fn(data):\n",
    "    pics = []\n",
    "    target = []\n",
    "    for item in data:\n",
    "\n",
    "        pics.append(numpy.array(item[0]))\n",
    "        target.append(item[1])\n",
    "    return {\n",
    "        'data': torch.from_numpy(numpy.array(pics)).float() / 255,\n",
    "        'target': torch.from_numpy(numpy.array(target)),\n",
    "    }\n",
    "\n",
    "# model\n",
    "model = AutoEncoder(28*28, 300, 64)\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "#optimizer\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#dataset\n",
    "dataset = datasets.MNIST('F:/Разное/Программирование/Школа Data Scientist/Project/Task 11 MNIST Полносвязная и сверточная сети', download=False)\n",
    "\n",
    "#loss\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "#dataloder\n",
    "for epoch in range(20):\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    print(f'epoch: {epoch + 1}')\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        data = batch['data'].to(device).view(batch['data'].size(0), -1)\n",
    "        optim.zero_grad()\n",
    "        predict = model(data)\n",
    "        loss = loss_func(predict, data)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if (step % 100 == 0):\n",
    "            print(loss)\n",
    "    \n",
    "test = dataset.data[100].view(1,-1).float() / 255\n",
    "predict = model(test)\n",
    "\n",
    "plt.imshow(test[0].view(28,28).detach().numpy())\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(predict[0].view(28,28).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fb0907",
   "metadata": {},
   "source": [
    "# Автокодировщик на сверточной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ebab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "tensor(0.1027, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0074, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21400045820>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    # #conv2d -> maxpool2d -> conv2d -> maxpool2d -> conv2d\n",
    "    def __init__(self, in_chan, hidden_chan):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_chan, hidden_chan, kernel_size = 5, stride = 1, padding = 2) # 28*28\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # 14*14\n",
    "        self.conv2 = nn.Conv2d(hidden_chan, hidden_chan, kernel_size = 3, stride = 1, padding = 1) # 14*14\n",
    "        self.pool2 = nn.MaxPool2d(2, 2) # 7*7\n",
    "        self.conv3 = nn.Conv2d(hidden_chan, 1, kernel_size = 3, stride = 1, padding = 1)\n",
    "                \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x): # 7*7\n",
    "        x = self.activation(self.pool1(self.conv1(x)))\n",
    "        x = self.activation(self.pool2(self.conv2(x)))\n",
    "        x = self.activation(self.conv3(x))\n",
    "          \n",
    "        return x\n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    # conv2d -> upsampling2d -> conv2d -> upsampling2d -> conv2d\n",
    "    def __init__(self, in_chan, hidden_chan):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, hidden_chan, kernel_size = 3, stride = 1, padding = 1) # 7*7\n",
    "        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2) # > 14 x 14\n",
    "        self.conv2 = nn.Conv2d(hidden_chan, hidden_chan, kernel_size=3, stride=1, padding=1)  # > 14 x 14\n",
    "        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)  # 28 x 28\n",
    "        self.conv3 = nn.Conv2d(hidden_chan, in_chan, kernel_size=5, stride=1, padding=2)\n",
    "                \n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x): # 28*28\n",
    "        x = self.activation(self.upsample1(self.conv1(x)))\n",
    "        x = self.activation(self.upsample2(self.conv2(x)))\n",
    "        x = self.activation(self.conv3(x))\n",
    "    \n",
    "        return x\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim)\n",
    "        self.decoder = Decoder(input_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def collate_fn(data):\n",
    "    pics = []\n",
    "    target = []\n",
    "    for item in data:\n",
    "\n",
    "        pics.append(numpy.array(item[0]))\n",
    "        target.append(item[1])\n",
    "    return {\n",
    "        'data': torch.from_numpy(numpy.array(pics)).float() / 255,\n",
    "        'target': torch.from_numpy(numpy.array(target)),\n",
    "    }\n",
    "\n",
    "# model\n",
    "model = AutoEncoder(1, 50)\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "#optimizer\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#dataset\n",
    "dataset = datasets.MNIST('F:/Разное/Программирование/Школа Data Scientist/Project/Task 11 MNIST Полносвязная и сверточная сети', download=False)\n",
    "\n",
    "#loss\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "#dataloder\n",
    "for epoch in range(1):\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    print(f'epoch: {epoch + 1}')\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        data = batch['data'].to(device).unsqueeze(1)\n",
    "        optim.zero_grad()\n",
    "        predict = model(data)\n",
    "        loss = loss_func(predict, data)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if (step % 100 == 0):\n",
    "            print(loss)\n",
    "    \n",
    "test = dataset.data[100].unsqueeze(0).unsqueeze(0).float() / 255\n",
    "predict = model(test)\n",
    "\n",
    "plt.imshow(test[0][0].view(28, 28).detach().numpy())\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(predict[0][0].squeeze().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d50cc8",
   "metadata": {},
   "source": [
    "# Вариационный автокодировщик VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe871409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "tensor(0.1187, grad_fn=<AddBackward0>)\n",
      "tensor(0.0659, grad_fn=<AddBackward0>)\n",
      "tensor(0.0663, grad_fn=<AddBackward0>)\n",
      "tensor(0.0674, grad_fn=<AddBackward0>)\n",
      "tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch: 2\n",
      "tensor(0.0671, grad_fn=<AddBackward0>)\n",
      "tensor(0.0659, grad_fn=<AddBackward0>)\n",
      "tensor(0.0647, grad_fn=<AddBackward0>)\n",
      "tensor(0.0690, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    # #conv2d -> maxpool2d -> conv2d -> maxpool2d -> conv2d\n",
    "    def __init__(self, in_chan, hidden_chan):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_chan, hidden_chan, kernel_size = 5, stride = 1, padding = 2) # 28*28\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)# 14*14\n",
    "        self.conv2 = nn.Conv2d(hidden_chan, hidden_chan, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(hidden_chan, hidden_chan, kernel_size = 3, stride = 1, padding = 1) # 14*14\n",
    "        self.pool2 = nn.MaxPool2d(2, 2) # 7*7\n",
    "        self.conv4 = nn.Conv2d(hidden_chan, hidden_chan, kernel_size = 2, stride = 2, padding = 4)\n",
    "        \n",
    "        self.conv_mu = nn.Conv2d(hidden_chan, 1, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_sigma = nn.Conv2d(hidden_chan, 1, kernel_size=3, stride=1, padding=1)\n",
    "                \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x): # 7*7\n",
    "        x = self.activation(self.pool1(self.conv1(x)))\n",
    "        x = self.activation(self.conv2(x))\n",
    "        x = self.activation(self.pool2(self.conv3(x)))\n",
    "        x = self.activation(self.conv4(x))\n",
    "        \n",
    "        return self.activation(self.conv_mu(x)), torch.exp(self.conv_sigma(x))\n",
    "\n",
    "# sampling\n",
    "def sampling(mu, sigma):\n",
    "    return mu + sigma * torch.normal(torch.zeros_like(mu), torch.ones_like(mu))\n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    # conv2d -> upsampling2d -> conv2d -> upsampling2d -> conv2d\n",
    "    def __init__(self, in_chan, hidden_chan):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, hidden_chan, kernel_size = 2, stride = 2, padding = 4)\n",
    "        self.conv2 = nn.Conv2d(hidden_chan, hidden_chan, kernel_size = 3, stride = 1, padding = 1) # 7*7\n",
    "        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2) # > 14 x 14\n",
    "        self.conv3 = nn.Conv2d(hidden_chan, hidden_chan, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(hidden_chan, hidden_chan, kernel_size=3, stride=1, padding=1)  # > 14 x 14\n",
    "        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)  # 28 x 28\n",
    "        self.conv5 = nn.Conv2d(hidden_chan, in_chan, kernel_size=5, stride=1, padding=2)\n",
    "                \n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x): # 28*28\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.activation(self.upsample1(self.conv2(x)))\n",
    "        x = self.activation(self.conv3(x))\n",
    "        x = self.activation(self.upsample2(self.conv4(x)))\n",
    "        x = self.activation(self.conv5(x))\n",
    "            \n",
    "        return x\n",
    "\n",
    "class AutoEncoderVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim)\n",
    "        self.decoder = Decoder(input_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.encoder(x)\n",
    "        x = self.decoder(sampling(mu, sigma))\n",
    "\n",
    "        return x, mu, sigma\n",
    "\n",
    "def collate_fn(data):\n",
    "    pics = []\n",
    "    target = []\n",
    "    for item in data:\n",
    "\n",
    "        pics.append(numpy.array(item[0]))\n",
    "        target.append(item[1])\n",
    "    return {\n",
    "        'data': torch.from_numpy(numpy.array(pics)).float() / 255,\n",
    "        'target': torch.from_numpy(numpy.array(target)),\n",
    "    }\n",
    "\n",
    "def kl_loss(mu, sigma):\n",
    "    p = torch.distributions.Normal(mu, sigma)\n",
    "    q = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(sigma))\n",
    "\n",
    "    return torch.distributions.kl_divergence(p, q).mean()\n",
    "\n",
    "# model\n",
    "model = AutoEncoderVAE(1, 200)\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "#optimizer\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#dataset\n",
    "dataset = datasets.MNIST('F:/Разное/Программирование/Школа Data Scientist/Project/Task 11 MNIST Полносвязная и сверточная сети', download=False)\n",
    "\n",
    "#loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#dataloder\n",
    "for epoch in range(3):\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    print(f'epoch: {epoch + 1}')\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        data = batch['data'].to(device).unsqueeze(1)\n",
    "        optim.zero_grad()\n",
    "        predict, mu, sigma = model(data)\n",
    "        #loss\n",
    "        loss = kl_loss(mu, sigma) + criterion(data, predict)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if (step % 100 == 0):\n",
    "            print(loss)\n",
    "\n",
    "test = dataset.data[100].unsqueeze(0).unsqueeze(0).float() / 255\n",
    "predict = model(test)\n",
    "\n",
    "plt.imshow(test[0][0].view(28, 28).detach().numpy())\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(predict[0][0].squeeze().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeac4fa",
   "metadata": {},
   "source": [
    "# Зашумленный автокодировщик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c909c72f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DNS\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:154: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:112.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1179, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2\n",
      "tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0805, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2112c71e670>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    # #conv2d -> maxpool2d -> conv2d -> maxpool2d -> conv2d\n",
    "    def __init__(self, in_chan, hidden_chan):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_chan, hidden_chan, kernel_size = 5, stride = 1, padding = 2) # 28*28\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # 14*14\n",
    "        self.conv2 = nn.Conv2d(hidden_chan, hidden_chan, kernel_size = 3, stride = 1, padding = 1) # 14*14\n",
    "        self.pool2 = nn.MaxPool2d(2, 2) # 7*7\n",
    "        self.conv3 = nn.Conv2d(hidden_chan, 1, kernel_size = 3, stride = 1, padding = 1)\n",
    "                \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x): # 7*7\n",
    "        x = self.activation(self.pool1(self.conv1(x)))\n",
    "        x = self.activation(self.pool2(self.conv2(x)))\n",
    "        x = self.activation(self.conv3(x))\n",
    "          \n",
    "        return x\n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    # conv2d -> upsampling2d -> conv2d -> upsampling2d -> conv2d\n",
    "    def __init__(self, in_chan, hidden_chan):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, hidden_chan, kernel_size = 3, stride = 1, padding = 1) # 7*7\n",
    "        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2) # > 14 x 14\n",
    "        self.conv2 = nn.Conv2d(hidden_chan, hidden_chan, kernel_size=3, stride=1, padding=1)  # > 14 x 14\n",
    "        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)  # 28 x 28\n",
    "        self.conv3 = nn.Conv2d(hidden_chan, in_chan, kernel_size=5, stride=1, padding=2)\n",
    "                \n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x): # 28*28\n",
    "        x = self.activation(self.upsample1(self.conv1(x)))\n",
    "        x = self.activation(self.upsample2(self.conv2(x)))\n",
    "        x = self.activation(self.conv3(x))\n",
    "    \n",
    "        return x\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim)\n",
    "        self.decoder = Decoder(input_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def collate_fn(data):\n",
    "    pics = []\n",
    "    target = []\n",
    "    for item in data:\n",
    "\n",
    "        pics.append(numpy.array(item[0]))\n",
    "        target.append(item[1])\n",
    "    return {\n",
    "        'data': torch.from_numpy(numpy.array(pics)).float() / 255,\n",
    "        'target': torch.from_numpy(numpy.array(target)),\n",
    "    }\n",
    "\n",
    "# model\n",
    "model = AutoEncoder(1, 50)\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "#optimizer\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#dataset\n",
    "dataset = datasets.MNIST('C:/Users/DNS/Documents/Школа Data Scientist/Project/Task 11 MNIST Полносвязная и сверточная сети', download=False)\n",
    "\n",
    "#loss\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "#dataloder\n",
    "for epoch in range(2):\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    print(f'epoch: {epoch + 1}')\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        data = batch['data'].to(device).unsqueeze(1)\n",
    "        data_noized = torch.clamp(data + torch.normal(torch.zeros_like(data), torch.ones_like(data)), 0., 1.)\n",
    "        optim.zero_grad()\n",
    "        predict = model(data_noized)\n",
    "        loss = loss_func(predict, data)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if (step % 100 == 0):\n",
    "            print(loss)\n",
    "    \n",
    "test = dataset.data[100].unsqueeze(0).unsqueeze(0).float() / 255\n",
    "test = torch.clamp(test + torch.normal(torch.zeros_like(test), torch.ones_like(test)), 0., 1.)\n",
    "predict = model(test)\n",
    "\n",
    "plt.imshow(test[0][0].view(28, 28).detach().numpy())\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(predict[0][0].squeeze().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06559ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
