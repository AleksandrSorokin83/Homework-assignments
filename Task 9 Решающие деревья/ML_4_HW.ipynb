{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/wine+quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "data = pd.read_csv(link, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Оцените качество по метрике accuracy для классификаторов:\n",
    "\n",
    "DecisionTreeClassifier\n",
    "\n",
    "BaggingClassifier со 100 деревьями\n",
    "\n",
    "RandomForestClassifier со 100 деревьями\n",
    "\n",
    "Сравните результаты и напишите какой вывод можно сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "Wall time: 1.83 s\n",
      "0.5672295184490307 \n",
      "\n",
      "BaggingClassifier(n_estimators=100)\n",
      "Wall time: 3.4 s\n",
      "0.555972482801751 \n",
      "\n",
      "DecisionTreeClassifier()\n",
      "Wall time: 65.5 ms\n",
      "0.4496560350218887 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "clfs = [RandomForestClassifier(n_estimators=100), BaggingClassifier(n_estimators=100), DecisionTreeClassifier()]\n",
    "\n",
    "for clf in clfs:\n",
    "    print(clf)\n",
    "    %time cvs = cross_val_score(clf, X, y, scoring='accuracy', cv=3).mean()\n",
    "    print(cvs, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат по метрике accuracy у RandomForestClassifier почти такой-же как и у BaggingClassifier, но скорость обучения быстрее в ~2 раза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Разделите выборку на обучающую и тестовую в отношении 70%/30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, test_size=.3, size=1, seed=42):\n",
    "    df_res = df.sample(int(df.shape[0]*size)).copy() if size != 1 else df.copy()\n",
    "    X_res, y_res = df_res.iloc[:,:-1], df_res.iloc[:,-1]\n",
    "    X_res_train, X_res_test, y_res_train, y_res_test = train_test_split(X_res, y_res, test_size=test_size, random_state=seed)\n",
    "    return df_res, X_res, y_res, X_res_train, X_res_test, y_res_train, y_res_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12) (1599, 11) (1119, 11) (480, 11)\n"
     ]
    }
   ],
   "source": [
    "df, X, y, X_train, X_test, y_train, y_test = split_df(data)\n",
    "print(df.shape, X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Посчитайте качество на тестовой выборке по метрике accuracy для классификатора RandomForestClassifier, используя значения деревьев:\n",
    "    \n",
    "10, 50, 100, 200, далее с шагом 200 до 5000 деревьев.\n",
    "Постройте график зависимости качества от числа деревьев.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = [10, 50, 100] + [n for n in range(200,5001,200)]\n",
    "scores = []\n",
    "\n",
    "for n in N:\n",
    "    clf = RandomForestClassifier(n_estimators=int(n), n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score_test = clf.score(X_test, y_test)\n",
    "    score_train = clf.score(X_train, y_train)\n",
    "    scores.append({'n':int(n), 'score_test':score_test, 'score_train':score_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b1351c0fa0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores)\n",
    "\n",
    "plt.plot(scores_df.n, scores_df.score_test)\n",
    "#plt.plot(scores_df.n, scores_df.score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек sklearn и xgboost. Сравните значение метрики accuracy по cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "Wall time: 16.4 s\n",
      "0.5628624608150471 \n",
      "\n",
      "XGBClassifier\n",
      "Wall time: 5.97 s\n",
      "0.5472335423197492 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "clfs = [{'name':'GradientBoostingClassifier', 'model':GradientBoostingClassifier()}, \n",
    "        {'name':'XGBClassifier', 'model':XGBClassifier(objective='multi:softprob', eval_metric='mlogloss')}]\n",
    "\n",
    "for clf in clfs:\n",
    "    clf_name = clf['name']\n",
    "    model = clf['model']\n",
    "    print(clf_name)\n",
    "    %time cvs = cross_val_score(model, X, y, scoring=\"accuracy\", cv=5).mean()\n",
    "    print(cvs, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Подберите оптимальные параметры этих алгоритмов с помощью GridSearchCV(cv=3).\n",
    "Параметры для оптимизации:\n",
    "\n",
    "оптимизируемый функционал\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните значение метрики accuracy и скорость работы. Выведите лучшие параметры алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ccp_alpha', 'criterion', 'init', 'learning_rate', 'loss', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_iter_no_change', 'random_state', 'subsample', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['objective', 'use_label_encoder', 'base_score', 'booster', 'colsample_bylevel', 'colsample_bynode', 'colsample_bytree', 'gamma', 'gpu_id', 'importance_type', 'interaction_constraints', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'missing', 'monotone_constraints', 'n_estimators', 'n_jobs', 'num_parallel_tree', 'random_state', 'reg_alpha', 'reg_lambda', 'scale_pos_weight', 'subsample', 'tree_method', 'validate_parameters', 'verbosity'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 34s\n",
      "GradientBoostingClassifier\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 30}\n",
      "Wall time: 16.1 s\n",
      "XGBClassifier\n",
      "{'eval_metric': 'mlogloss', 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 20, 'objective': 'multi:softprob'}\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {\n",
    "        'clf': GradientBoostingClassifier,\n",
    "        'params': [{\n",
    "            'criterion': ['friedman_mse', 'mae'],\n",
    "            'learning_rate': [.1, .5, .9],\n",
    "            'n_estimators': [10, 20, 30], \n",
    "            'max_depth': [2, 3, 4]\n",
    "        }]\n",
    "    }, {\n",
    "        'clf': XGBClassifier,\n",
    "        'params': [{\n",
    "            'objective': ['multi:softprob'],\n",
    "            'eval_metric': ['mlogloss', 'mae'],\n",
    "            'learning_rate': [.1, .5, .9],\n",
    "            'n_estimators': [10, 20, 30],  \n",
    "            'max_depth': [2, 3, 4]\n",
    "        }]\n",
    "    }\n",
    "]\n",
    "\n",
    "cv_dfs = []\n",
    "\n",
    "for model in models:\n",
    "    clf_name = model['clf'].__name__\n",
    "    clf = model['clf']\n",
    "    params = model['params']\n",
    "    %time search = GridSearchCV(clf(), param_grid=params, scoring='accuracy', cv=3, n_jobs=-1).fit(X, y)\n",
    "    cv_df = pd.DataFrame(search.cv_results_)\n",
    "    cv_df['clf_name'] = clf_name\n",
    "    cv_dfs.append(cv_df)\n",
    "    print(clf_name)\n",
    "    print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf_name</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_eval_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.585991</td>\n",
       "      <td>0.473943</td>\n",
       "      <td>0.010416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>mlogloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.552220</td>\n",
       "      <td>0.123238</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>mlogloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.585991</td>\n",
       "      <td>0.458318</td>\n",
       "      <td>0.010416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         clf_name  mean_test_score  mean_fit_time  mean_score_time  \\\n",
       "61  XGBClassifier         0.585991       0.473943         0.010416   \n",
       "72  XGBClassifier         0.552220       0.123238         0.005383   \n",
       "88  XGBClassifier         0.585991       0.458318         0.010416   \n",
       "\n",
       "   param_criterion param_learning_rate param_max_depth param_n_estimators  \\\n",
       "61             NaN                 0.1               4                 20   \n",
       "72             NaN                 0.9               2                 10   \n",
       "88             NaN                 0.1               4                 20   \n",
       "\n",
       "   param_eval_metric  \n",
       "61          mlogloss  \n",
       "72          mlogloss  \n",
       "88               mae  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs_df = pd.concat(cv_dfs).reset_index(drop=True)\n",
    "best_models = cvs_df[\n",
    "        (cvs_df.mean_fit_time == cvs_df.mean_fit_time.min()) |\n",
    "        #(cvs_df.mean_score_time == cvs_df.mean_score_time.min()) | \n",
    "        (cvs_df.mean_test_score == cvs_df.mean_test_score.max())]\n",
    "best_models = best_models[[\n",
    "        'clf_name',\n",
    "        'mean_test_score',\n",
    "        'mean_fit_time',\n",
    "        'mean_score_time',\n",
    "        'param_criterion',\n",
    "        'param_learning_rate',\n",
    "        'param_max_depth',\n",
    "        'param_n_estimators',\n",
    "        'param_eval_metric'\n",
    "]]\n",
    "best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек lightgbm и catboost. Сравните значение метрики accuracy по cross_val_score по всем четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.2-py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: wheel in c:\\users\\dns\\anaconda3\\lib\\site-packages (from lightgbm) (0.36.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\dns\\anaconda3\\lib\\site-packages (from lightgbm) (1.6.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\dns\\anaconda3\\lib\\site-packages (from lightgbm) (0.24.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dns\\anaconda3\\lib\\site-packages (from lightgbm) (1.20.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\dns\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dns\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.0.4-cp38-none-win_amd64.whl (73.5 MB)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.6.0-py2.py3-none-any.whl (27.7 MB)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\dns\\anaconda3\\lib\\site-packages (from catboost) (1.20.1)\n",
      "Requirement already satisfied: six in c:\\users\\dns\\appdata\\roaming\\python\\python38\\site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\dns\\anaconda3\\lib\\site-packages (from catboost) (1.6.2)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\dns\\anaconda3\\lib\\site-packages (from catboost) (1.2.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dns\\anaconda3\\lib\\site-packages (from catboost) (3.3.4)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.19.1-py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\dns\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\dns\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\dns\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dns\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dns\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dns\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (8.2.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly, graphviz, catboost\n",
      "Successfully installed catboost-1.0.4 graphviz-0.19.1 plotly-5.6.0 tenacity-8.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier \n",
      "\n",
      "Wall time: 9.74 s\n",
      "cross_val_score -  0.5403377110694184 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier\n",
    "print(model.__name__, '\\n')\n",
    "      \n",
    "%time cvs = cross_val_score(model(), X, y, scoring=\"accuracy\", cv=3).mean()\n",
    "print('cross_val_score - ', cvs, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier \n",
      "\n",
      "Wall time: 3.22 s\n",
      "cross_val_score -  0.5284552845528455 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier\n",
    "print(model.__name__, '\\n')\n",
    "      \n",
    "%time cvs = cross_val_score(model(objective='multi:softprob', eval_metric='mlogloss'), X, y, scoring=\"accuracy\", cv=3).mean()\n",
    "print('cross_val_score - ', cvs, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier \n",
      "\n",
      "Wall time: 4.42 s\n",
      "cross_val_score -  0.5284552845528455 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier\n",
    "print(model.__name__, '\\n')\n",
    "      \n",
    "%time cvs = cross_val_score(model(), X, y, scoring=\"accuracy\", cv=3).mean()\n",
    "print('cross_val_score - ', cvs, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostClassifier \n",
      "\n",
      "Wall time: 46.4 s\n",
      "cross_val_score -  0.5328330206378987 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier\n",
    "print(model.__name__, '\\n')\n",
    "      \n",
    "%time cvs = cross_val_score(model(verbose=False), X, y, scoring=\"accuracy\", cv=3).mean()\n",
    "print('cross_val_score - ', cvs, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Подберите оптимальные параметры для алгоритмов градиентного бустинга из библиотек lightgbm и catboost с теми же условиями. Выведите лучшие параметры алгоритмов.\n",
    "Сравните значение метрики accuracy и скорость по этим четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boosting_type', 'class_weight', 'colsample_bytree', 'importance_type', 'learning_rate', 'max_depth', 'min_child_samples', 'min_child_weight', 'min_split_gain', 'n_estimators', 'n_jobs', 'num_leaves', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'silent', 'subsample', 'subsample_for_bin', 'subsample_freq'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBMClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nan_mode': 'Min',\n",
       " 'eval_metric': 'MultiClass',\n",
       " 'iterations': 1000,\n",
       " 'sampling_frequency': 'PerTree',\n",
       " 'leaf_estimation_method': 'Newton',\n",
       " 'grow_policy': 'SymmetricTree',\n",
       " 'penalties_coefficient': 1,\n",
       " 'boosting_type': 'Plain',\n",
       " 'model_shrink_mode': 'Constant',\n",
       " 'feature_border_type': 'GreedyLogSum',\n",
       " 'bayesian_matrix_reg': 0.10000000149011612,\n",
       " 'force_unit_auto_pair_weights': False,\n",
       " 'l2_leaf_reg': 3,\n",
       " 'random_strength': 1,\n",
       " 'rsm': 1,\n",
       " 'boost_from_average': False,\n",
       " 'model_size_reg': 0.5,\n",
       " 'pool_metainfo_options': {'tags': {}},\n",
       " 'use_best_model': False,\n",
       " 'class_names': [3, 4, 5, 6, 7, 8],\n",
       " 'random_seed': 0,\n",
       " 'depth': 6,\n",
       " 'posterior_sampling': False,\n",
       " 'border_count': 254,\n",
       " 'bagging_temperature': 1,\n",
       " 'classes_count': 0,\n",
       " 'auto_class_weights': 'None',\n",
       " 'sparse_features_conflict_fraction': 0,\n",
       " 'leaf_estimation_backtracking': 'AnyImprovement',\n",
       " 'best_model_min_trees': 1,\n",
       " 'model_shrink_rate': 0,\n",
       " 'min_data_in_leaf': 1,\n",
       " 'loss_function': 'MultiClass',\n",
       " 'learning_rate': 0.08104400336742401,\n",
       " 'score_function': 'Cosine',\n",
       " 'task_type': 'CPU',\n",
       " 'leaf_estimation_iterations': 1,\n",
       " 'bootstrap_type': 'Bayesian',\n",
       " 'max_leaves': 64}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CatBoostClassifier(verbose=False).fit(X,y).get_all_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "Wall time: 33.9 s\n",
      "LGBMClassifier\n",
      "{'eval_metric': 'mlogloss', 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 20, 'objective': 'multi:softprob'} \n",
      "\n",
      "Wall time: 32.3 s\n",
      "CatBoostClassifier\n",
      "{'eval_metric': 'MultiClass', 'learning_rate': 0.1, 'loss_function': 'MultiClass', 'max_depth': 4, 'n_estimators': 30, 'verbose': False} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {\n",
    "        'clf': LGBMClassifier,\n",
    "        'params': [{\n",
    "            'objective': ['multi:softprob'],\n",
    "            'eval_metric': ['mlogloss', 'mae'],\n",
    "            'learning_rate': [.1, .5, .9],\n",
    "            'n_estimators': [10, 20, 30],  \n",
    "            'max_depth': [2, 3, 4]}]\n",
    "    }, {\n",
    "        'clf': CatBoostClassifier,\n",
    "        'params': [{\n",
    "            'loss_function': ['MultiClass'],\n",
    "            'eval_metric': ['MultiClass'],\n",
    "            'learning_rate': [.1, .5, .9],\n",
    "            'n_estimators': [10, 20, 30],  \n",
    "            'max_depth': [2, 3, 4],\n",
    "            'verbose': [False]}]\n",
    "    }\n",
    "]\n",
    "\n",
    "cv_dfs = []\n",
    "\n",
    "for model in models:\n",
    "    clf_name = model['clf'].__name__\n",
    "    clf = model['clf']\n",
    "    params = model['params']\n",
    "    %time search = GridSearchCV(clf(), param_grid=params, scoring='accuracy', cv=3, n_jobs=-1).fit(X, y)\n",
    "    cv_df = pd.DataFrame(search.cv_results_)\n",
    "    cv_df['clf_name'] = clf_name\n",
    "    cv_dfs.append(cv_df)\n",
    "    print(clf_name)\n",
    "    print(search.best_params_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf_name</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_eval_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.558474</td>\n",
       "      <td>0.046872</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.587867</td>\n",
       "      <td>0.907220</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>MultiClass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              clf_name  mean_test_score  mean_fit_time  mean_score_time  \\\n",
       "27      LGBMClassifier         0.558474       0.046872         0.015626   \n",
       "62  CatBoostClassifier         0.587867       0.907220         0.004001   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators param_eval_metric  \n",
       "27                 0.1               2                 10               mae  \n",
       "62                 0.1               4                 30        MultiClass  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs_df = pd.concat(cv_dfs).reset_index(drop=True)\n",
    "best_models = cvs_df[\n",
    "        (cvs_df.mean_fit_time == cvs_df.mean_fit_time.min()) |\n",
    "        #(cvs_df.mean_score_time == cvs_df.mean_score_time.min()) | \n",
    "        (cvs_df.mean_test_score == cvs_df.mean_test_score.max())]\n",
    "best_models = best_models[[\n",
    "        'clf_name',\n",
    "        'mean_test_score',\n",
    "        'mean_fit_time',\n",
    "        'mean_score_time',\n",
    "        'param_learning_rate',\n",
    "        'param_max_depth',\n",
    "        'param_n_estimators',\n",
    "        'param_eval_metric'\n",
    "]]\n",
    "best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.Подберите оптимальные параметры алгоритма из библиотеки xgbost с помощью [hyperopt](https://github.com/hyperopt/hyperopt) . Параметры для оптимизации:\n",
    "\n",
    "оптимизируемый функционал\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните результат с поиском по сетке из sklearn. Выведите лучшие параметры алгоритма, найденные даным способом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\dns\\anaconda3\\lib\\site-packages (from hyperopt) (1.6.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\dns\\anaconda3\\lib\\site-packages (from hyperopt) (1.6.2)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\dns\\anaconda3\\lib\\site-packages (from hyperopt) (2.5)\n",
      "Requirement already satisfied: six in c:\\users\\dns\\appdata\\roaming\\python\\python38\\site-packages (from hyperopt) (1.15.0)\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\dns\\anaconda3\\lib\\site-packages (from hyperopt) (1.20.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dns\\anaconda3\\lib\\site-packages (from hyperopt) (4.59.0)\n",
      "Requirement already satisfied: future in c:\\users\\dns\\anaconda3\\lib\\site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\dns\\anaconda3\\lib\\site-packages (from networkx>=2.2->hyperopt) (5.0.6)\n",
      "Installing collected packages: py4j, hyperopt\n",
      "Successfully installed hyperopt-0.2.7 py4j-0.10.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from functools import partial\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:52<00:00,  1.32s/trial, best loss: -0.5778611632270169]\n",
      "name - xgbc\n",
      "loss - -0.5778611632270169\n",
      "eval_metric - mae\n",
      "learning_rate - 0.06778686793546025\n",
      "max_depth - 5\n",
      "n_estimators - 31\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {'name':'xgbc', 'clf':XGBClassifier(), 'eval_metrics':['mlogloss', 'mae']}\n",
    "]\n",
    "\n",
    "def objective(params, pipe,  X_train, y_train):\n",
    "    pipe.set_params(**params)\n",
    "    score = cross_val_score(estimator=pipe, X=X_train, y=y_train, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "    return {'loss': -score.mean(), 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "for model in models:\n",
    "    name = model['name']\n",
    "    clf = model['clf']\n",
    "    eval_metrics = model['eval_metrics']\n",
    "    pipe = Pipeline([(name, clf)])\n",
    "    search_space = {\n",
    "        name+'__eval_metric': hp.choice(label=\"eval_metric\", options=eval_metrics),\n",
    "        name+'__learning_rate' : hp.loguniform(label='learning_rate', low=np.log(0.04), high=np.log(0.5)),\n",
    "        name+'__max_depth' :  hp.choice(label=\"max_depth\", options=np.arange(2, 10, 1, dtype=int)),\n",
    "        name+'__n_estimators' : hp.choice(label=\"n_estimators\", options=np.arange(1, 100, 10, dtype=int))\n",
    "    }\n",
    "    trials = Trials()\n",
    "    best = fmin( \n",
    "        fn=partial(objective, pipe=pipe, X_train=X, y_train=y),\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=40,\n",
    "        trials=trials,\n",
    "        show_progressbar=True\n",
    "    )\n",
    "    print('name -', name)\n",
    "    print('loss -', trials.best_trial['result']['loss'])\n",
    "    for param_name in trials.best_trial['result']['params']:\n",
    "        print(param_name.split('__')[1], '-', trials.best_trial['result']['params'][param_name])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.Выведите качество по метрике accuracy стэкинга (StackingClassifier) 4-х алгоритмов с базовыми параметрами градиентного бустинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5716072545340838"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('cbc', CatBoostClassifier()),\n",
    "    ('lgbmc', LGBMClassifier()),\n",
    "    ('rfc', GradientBoostingClassifier()),\n",
    "    ('xgbc', XGBClassifier())\n",
    "]\n",
    "stacked = StackingClassifier(estimators=estimators)\n",
    "%time score = cross_val_score(estimator=stacked, X=X, y=y, scoring='accuracy', cv=3, n_jobs=-1).mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.Выведите качество по метрике accuracy стэкинга 4-х алгоритмов с оптимальными параметрами градиентного бустинга. Сравните результаты с предыдущим шагом и напишите какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [06:21<00:00,  9.53s/trial, best loss: -0.5672295184490306]\n",
      "name - gbc\n",
      "loss - -0.5672295184490306\n",
      "criterion - friedman_mse\n",
      "learning_rate - 0.13432959928135185\n",
      "max_depth - 2\n",
      "n_estimators - 11\n",
      "\n",
      "\n",
      "100%|██████████| 40/40 [00:38<00:00,  1.05trial/s, best loss: -0.5734834271419638]\n",
      "name - xgbc\n",
      "loss - -0.5734834271419638\n",
      "eval_metric - mlogloss\n",
      "learning_rate - 0.049920351482628994\n",
      "max_depth - 3\n",
      "n_estimators - 91\n",
      "\n",
      "\n",
      "100%|██████████| 40/40 [00:25<00:00,  1.56trial/s, best loss: -0.5741088180112571]\n",
      "name - lgbmc\n",
      "loss - -0.5741088180112571\n",
      "eval_metric - mae\n",
      "learning_rate - 0.06910870089098411\n",
      "max_depth - 2\n",
      "n_estimators - 31\n",
      "\n",
      "\n",
      "100%|██████████| 40/40 [02:08<00:00,  3.20s/trial, best loss: -0.5897435897435898]\n",
      "name - cbc\n",
      "loss - -0.5897435897435898\n",
      "eval_metric - MultiClass\n",
      "learning_rate - 0.10526074027527044\n",
      "max_depth - 5\n",
      "n_estimators - 51\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {'name':'gbc', 'clf':GradientBoostingClassifier(), \n",
    "     'metrics':{'param_name':'criterion','param_vals':['friedman_mse', 'mae']}},\n",
    "    {'name':'xgbc', 'clf':XGBClassifier(),\n",
    "     'metrics':{'param_name':'eval_metric','param_vals':['mlogloss', 'mae']}},\n",
    "    {'name':'lgbmc', 'clf':LGBMClassifier(objective='multi:softprob'),\n",
    "     'metrics':{'param_name':'eval_metric','param_vals':['mlogloss', 'mae']}},\n",
    "    {'name':'cbc', 'clf':CatBoostClassifier(loss_function='MultiClass'),\n",
    "     'metrics':{'param_name':'eval_metric','param_vals':['MultiClass']}},\n",
    "]\n",
    "\n",
    "def objective(params, pipe,  X_train, y_train):\n",
    "    pipe.set_params(**params)\n",
    "    score = cross_val_score(estimator=pipe, X=X_train, y=y_train, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "    return {'loss': -score.mean(), 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "best_trials = {}\n",
    "\n",
    "for model in models:\n",
    "    name = model['name']\n",
    "    clf = model['clf']\n",
    "    param_name = model['metrics']['param_name']\n",
    "    param_vals = model['metrics']['param_vals']\n",
    "    pipe = Pipeline([(name, clf)])\n",
    "    search_space = {\n",
    "        name+'__'+param_name: hp.choice(label=param_name, options=param_vals),\n",
    "        name+'__learning_rate' : hp.loguniform(label='learning_rate', low=np.log(0.04), high=np.log(0.5)),\n",
    "        name+'__max_depth' :  hp.choice(label=\"max_depth\", options=np.arange(2, 10, 1, dtype=int)),\n",
    "        name+'__n_estimators' : hp.choice(label=\"n_estimators\", options=np.arange(1, 100, 10, dtype=int))\n",
    "    }\n",
    "    trials = Trials()\n",
    "    best = fmin( \n",
    "        fn=partial(objective, pipe=pipe, X_train=X, y_train=y),\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=40,\n",
    "        trials=trials,\n",
    "        show_progressbar=True\n",
    "    )\n",
    "    best_trials[name] = trials.best_trial\n",
    "    print('name -', name)\n",
    "    print('loss -', trials.best_trial['result']['loss'])\n",
    "    for param_name in trials.best_trial['result']['params']:\n",
    "        print(param_name.split('__')[1], '-', trials.best_trial['result']['params'][param_name])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5834896810506567"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs = {'gbc':GradientBoostingClassifier, 'xgbc':XGBClassifier, 'lgbmc':LGBMClassifier, 'cbc':CatBoostClassifier}\n",
    "optimal_models = []\n",
    "for name in best_trials:\n",
    "    params = best_trials[name]['result']['params']\n",
    "    renamed_params = {}\n",
    "    for param_name in params:\n",
    "        renamed_name = param_name.split('__')[1]\n",
    "        renamed_params[renamed_name] = params[param_name]\n",
    "    model = clfs[name]\n",
    "    optimal_model = model(**renamed_params)\n",
    "    optimal_models.append((name, optimal_model))\n",
    "\n",
    "stacked = StackingClassifier(estimators=optimal_models)\n",
    "%time score = cross_val_score(estimator=stacked, X=X, y=y, scoring='accuracy', cv=3, n_jobs=-1).mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стэкинг моделей с оптимальными параметрами, показывает более лучший результат по метрике и по времени обучения. Вывод- данный ансамблевый лучше применять на предподготовленных моделях с заранее подобранными оптимальными параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
